{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.csv')\n",
    "df.columns = ['restaurant_id', 'city', 'cuisine', 'ranking', 'rating',\n",
    "              'price_range', 'reviews_count', 'reviews', 'url_ta', 'id_ta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Вспомогательные функции</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_list(string):\n",
    "    if type(string) is str:\n",
    "        return string.strip('][').replace('\\'', '').split(', ')\n",
    "    if type(string) is list:\n",
    "        return string\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_unique_values_from(series):\n",
    "    result = set()\n",
    "    for value in series.values:\n",
    "        if value == value:\n",
    "            values_list = convert_string_to_list(value)\n",
    "            for subvalue in values_list:\n",
    "                if subvalue != '':\n",
    "                    result.add(subvalue)\n",
    "    return result\n",
    "\n",
    "\n",
    "df_length = df.shape[0]\n",
    "\n",
    "def create_zeros_series():\n",
    "    return pd.Series(np.zeros(df_length), dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код по очистке данных и генерации новых признаков\n",
    "# При необходимости добавьте ячейки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим столбцы, не представляющие ценности\n",
    "df.drop(['restaurant_id','url_ta', 'id_ta'], 1, inplace=True)\n",
    "\n",
    "# заполним пропуски в reviews_count\n",
    "df.reviews_count = df.reviews_count.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Города</h3>\n",
    "\n",
    "сгенерируем dummy переменные для городов (в последствии я увидел хороший способ на kaggle, через get_dummies, но я решил оставить как есть, потому что так честно)\n",
    "к тому же, я возможно еще буду использовать этот столбец для группировки далее (хотя ничто не мешало мне точно так же сгенерировать dummy после использования столбца :D )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = get_unique_values_from(df.city)\n",
    "for city in cities:\n",
    "    df[city] = df.city.apply(lambda x: 1 if city == x else 0)\n",
    "\n",
    "# в курсе был вопрос, какие еще можно параметры извлечь из городов, а так же \n",
    "# на звонке с куратором по проекту поднимался вопрос. собственно там я и предложил возможно имеет смысл\n",
    "# взять численность населения в городах. попробуем\n",
    "populations = {'Amsterdam': 1148972,\n",
    "              'Athens': 3153355,\n",
    "              'Barcelona': 5585556,\n",
    "              'Berlin': 3562038,\n",
    "              'Bratislava': 424428,\n",
    "              'Brussels': 2080788,\n",
    "              'Budapest': 1768073,\n",
    "              'Copenhagen': 1346485,\n",
    "              'Dublin': 1228179,\n",
    "              'Edinburgh': 536775,\n",
    "              'Geneva': 613373,\n",
    "              'Hamburg': 1789954,\n",
    "              'Helsinki': 1304851,\n",
    "              'Krakow': 768731,\n",
    "              'Lisbon': 2956879,\n",
    "              'Ljubljana': 279631,\n",
    "              'London': 9304016,\n",
    "              'Luxembourg': 613894,\n",
    "              'Lyon': 1719268,\n",
    "              'Madrid': 6617513,\n",
    "              'Milan': 3140181,\n",
    "              'Munich': 1538302,\n",
    "              'Oporto': 1312947,\n",
    "              'Oslo': 1041377,\n",
    "              'Paris': 11017230,\n",
    "              'Prague': 1305737,\n",
    "              'Rome': 4257056,\n",
    "              'Stockholm': 1632798,\n",
    "              'Vienna': 1929944,\n",
    "              'Warsaw': 1783251,\n",
    "              'Zurich': 1395356}\n",
    "\n",
    "# добавим значения в датафрейм\n",
    "df['populations'] = df.city.apply(lambda x: populations[x])\n",
    "\n",
    "# нормализуем значения\n",
    "cities_scaler = MinMaxScaler()\n",
    "result = cities_scaler.fit_transform(np.array(df.populations).reshape(-1, 1)).reshape(1, -1)[0]\n",
    "df.populations = pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Разберем типы кухонь</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним пропуски\n",
    "df.cuisine = df.cuisine.fillna('')\n",
    "\n",
    "# получим все уникальные кухни из датасета\n",
    "cuisines = get_unique_values_from(df.cuisine)\n",
    "\n",
    "# добавим новые столбцы в датасет для каждого типа кухонь, 1 говорит что кухня присутствует в данном ресторане\n",
    "for cuisine in cuisines:\n",
    "    df[cuisine] = df.cuisine.apply(lambda x: 1 if cuisine in x else 0)\n",
    "    \n",
    "# в столбец cuisiune запишем количество кухонь представленных в ресторане\n",
    "def update_cuisines_count(row):\n",
    "    cuisines_list = row[list(cuisines)] #получаем часть строки, в которой хранятся все столбцы с кухнями\n",
    "    row['cuisine'] = sum(cuisines_list) # количество кухонь равно сумме всех единиц в списке возможных кухонь\n",
    "    return row\n",
    "\n",
    "df = df.apply(update_cuisines_count, axis=1)\n",
    "\n",
    "# переименуем колонку\n",
    "if 'cuisine_count' not in df.columns:\n",
    "    df.rename(columns={'cuisine': 'cuisine_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Разбор дат отзывов</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получим даты из строки с отзывами и обработаем их\n",
    "def get_review_dates_from(row):\n",
    "    reviews = row['reviews']\n",
    "    dates = re.findall(r'\\d{2}/\\d{2}/\\d{4}', reviews)\n",
    "    datetimes = list(map(pd.to_datetime, dates))\n",
    "    row['last_review_date'] = pd.NaT if not datetimes else max(datetimes)\n",
    "    row['previous_review_date'] = pd.NaT if not datetimes else min(datetimes)\n",
    "    row['days_between_reviews'] = 0 if not datetimes else (row['last_review_date'] - row['previous_review_date']).days\n",
    "    return row\n",
    "\n",
    "# добавим новые столбцы для дат последнего/предпоследнего отзывов,\n",
    "# а так же для количества дней между отзывами\n",
    "if 'last_review_date' not in df.columns:\n",
    "    df['last_review_date'] = create_zeros_series()\n",
    "    df['previous_review_date'] = create_zeros_series()\n",
    "    df['days_between_reviews'] = create_zeros_series()\n",
    "    df = df.apply(get_review_dates_from, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Разбор тональности отзывов</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "изначально, я планировал просто удалить оставшийся столбец с отзывами, но затем я вспомнил о материале об определении тональности текста из курса по ML и решил сделать свой, только на минималках :) я добавлю два столбца 'has_good_vibes', и 'has_bad_vibes', в который буду записывать 1/0 если в тексте отзывов есть \"хорошие\" слова типа \"good, perfect, excellent\", или плохие \"bad, poor, unsatisfied\" и т.д. при этом я понимаю что могут быть случаи типа \"not bad\", и всех их я не могу обработать, поэтому постараюсь покрыть максимальное количество слов/словосочетаний :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = ['good', 'perfect', 'not bad', 'excellent',\n",
    "              'great', ' fine ', 'exceptional', 'super',\n",
    "              'nice', 'positive', 'satisfying', 'acceptable']\n",
    "bad_words = [' bad ', 'awful', 'poor', ' sad ', 'unacceptable',\n",
    "             'garbage', 'junky', 'not good']\n",
    "\n",
    "def determine_reviews_vibe_for(row):\n",
    "    reviews = row['reviews']\n",
    "    # возможно, следовало бы обрабатывать одновременно наличие хороших и отстутсвие плохих\n",
    "    # оттенков в отзывах (и наоборот), но это сильно повлияет на производительность, поэтому\n",
    "    # будем считать что все отзывы могут быть только одной тональности\n",
    "    for word in good_words:\n",
    "        if word in reviews:\n",
    "            row['has_good_vibes'] = 1\n",
    "    for word in bad_words:\n",
    "        if word in reviews:\n",
    "            row['has_bad_vibes'] = 1\n",
    "    return row\n",
    "            \n",
    "if 'has_good_vibes' not in df.columns:\n",
    "    df['has_good_vibes'] = create_zeros_series()\n",
    "    df['has_bad_vibes'] = create_zeros_series()\n",
    "    df = df.apply(determine_reviews_vibe_for, axis=1)\n",
    "\n",
    "\n",
    "# на этом этапе, думаю, столбец reviews можно удалить за ненадобностью\n",
    "if 'reviews' in df.columns:\n",
    "    df.drop(['reviews'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Разбор рейтингов по городам</h3>\n",
    "предлагаю нормализовать данные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "result = scaler.fit_transform(np.array(df.ranking).reshape(-1, 1)).reshape(1, -1)[0]\n",
    "df.ranking = pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Разбор диапазона цен</h3>\n",
    "заменим условные обозначения на упорядоченные признаки, т.е. 1 - низкие цены ($), 3 - высокие и подумаем как заполнить пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price_range.value_counts(dropna=False)\n",
    "price_dict = {'$': 1,\n",
    "              '$$ - $$$': 2,\n",
    "              '$$$$': 3}\n",
    "if df.price_range.dtype == 'object':\n",
    "    df.price_range = df.price_range.apply(lambda x: 0 if x != x else price_dict[x])\n",
    "\n",
    "# для заполнения пропусков возьмем медианное значение цены в данном городе\n",
    "median_group = df.groupby(by=['city'])['price_range'].median()\n",
    "# видим что в двух городах медианное значение == 0, заменим их на 1\n",
    "median_group['Bratislava'] = 1\n",
    "median_group['Hamburg'] = 1\n",
    "\n",
    "#заполним пропуски\n",
    "df.price_range = np.where(df['price_range'] == 0, median_group[df['city']], df['price_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Работа с моделью</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели\n",
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "X = df.drop(['city', 'rating', 'last_review_date', 'previous_review_date'], axis = 1)\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.209677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ranking                 0.461968\n",
       "populations             0.181799\n",
       "reviews_count           0.154269\n",
       "days_between_reviews    0.032090\n",
       "cuisine_count           0.013108\n",
       "Prague                  0.009108\n",
       "Amsterdam               0.008385\n",
       "Rome                    0.007639\n",
       "price_range             0.005688\n",
       "Paris                   0.004507\n",
       "Helsinki                0.004448\n",
       "Milan                   0.004320\n",
       "Brussels                0.003916\n",
       "London                  0.003571\n",
       "Vienna                  0.003568\n",
       "dtype: float64"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "feat_importances = pd.Series(regr.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
